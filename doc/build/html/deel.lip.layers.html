

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>deel.lip.layers module &mdash; deel-lip 2.0 documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="deel.lip.losses module" href="deel.lip.losses.html" />
    <link rel="prev" title="deel.lip.initializers module" href="deel.lip.initializers.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> deel-lip
          

          
            
            <img src="_static/logo_white.svg" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Contents:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="deel.lip.activations.html">deel.lip.activations module</a></li>
<li class="toctree-l1"><a class="reference internal" href="deel.lip.callbacks.html">deel.lip.callbacks module</a></li>
<li class="toctree-l1"><a class="reference internal" href="deel.lip.constraints.html">deel.lip.constraints module</a></li>
<li class="toctree-l1"><a class="reference internal" href="deel.lip.initializers.html">deel.lip.initializers module</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">deel.lip.layers module</a></li>
<li class="toctree-l1"><a class="reference internal" href="deel.lip.losses.html">deel.lip.losses module</a></li>
<li class="toctree-l1"><a class="reference internal" href="deel.lip.model.html">deel.lip.model module</a></li>
<li class="toctree-l1"><a class="reference internal" href="deel.lip.normalizers.html">deel.lip.normalizers module</a></li>
<li class="toctree-l1"><a class="reference internal" href="deel.lip.utils.html">deel.lip.utils module</a></li>
<li class="toctree-l1"><a class="reference internal" href="wasserstein_toy.html">Demo 1: Wasserstein distance estimation on toy example</a></li>
<li class="toctree-l1"><a class="reference internal" href="wassersteinClassif_toy.html">Demo 2: HKR Classifier on toy dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="wassersteinClassif_MNIST08.html">Demo 3: HKR classifier on MNIST dataset</a></li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">deel-lip</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html">Docs</a> &raquo;</li>
        
      <li>deel.lip.layers module</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="_sources/deel.lip.layers.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div class="section" id="module-deel.lip.layers">
<span id="deel-lip-layers-module"></span><h1>deel.lip.layers module<a class="headerlink" href="#module-deel.lip.layers" title="Permalink to this headline">¶</a></h1>
<p>This module extends original keras layers, in order to add k lipschitz constraint via reparametrization.
Currently, are implemented:</p>
<ul class="simple">
<li><p>Dense layer: as SpectralDense ( and as FrobeniusDense when the layer has a single output )</p></li>
<li><p>Conv2D layer: as SpectralConv2D ( and as FrobeniusConv2D when the layer has a single output )</p></li>
<li><p>AveragePooling: as ScaledAveragePooling</p></li>
<li><p>GlobalAveragePooling2D: as ScaledGlobalAveragePooling2D</p></li>
</ul>
<p>By default the layers are 1 Lipschitz almost everywhere, which is efficient for wasserstein distance estimation. However
for other problems (such as adversarial robustness ) the user may want to use layers that are at most 1 lipschitz, this
can be done by setting the param <cite>niter_bjorck=0</cite>.</p>
<dl class="class">
<dt id="deel.lip.layers.Condensable">
<em class="property">class </em><code class="sig-prename descclassname">deel.lip.layers.</code><code class="sig-name descname">Condensable</code><a class="headerlink" href="#deel.lip.layers.Condensable" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>Some Layers don’t optimize directly the kernel, this means that the kernel stored in the layer is not the kernel
used to make predictions (called W_bar), to address this, these layers can implement the condense() function that
make self.kernel equal to W_bar.</p>
<p>This operation also allow the turn the lipschitz layer to it keras equivalent ie. The Dense layer that have the same
predictions as the trained SpectralDense.</p>
<dl class="method">
<dt id="deel.lip.layers.Condensable.condense">
<code class="sig-name descname">condense</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.Condensable.condense" title="Permalink to this definition">¶</a></dt>
<dd><p>The condense operation allow to overwrite the kernel and ensure that other variables are still consistent.</p>
<p>Returns:</p>
</dd></dl>

<dl class="method">
<dt id="deel.lip.layers.Condensable.vanilla_export">
<code class="sig-name descname">vanilla_export</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.Condensable.vanilla_export" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation allow to turn this Layer to it’s super type, easing storage and serving.</p>
<p>Returns: self as super type</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deel.lip.layers.FrobeniusConv2D">
<em class="property">class </em><code class="sig-prename descclassname">deel.lip.layers.</code><code class="sig-name descname">FrobeniusConv2D</code><span class="sig-paren">(</span><em class="sig-param">filters</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">strides=(1</em>, <em class="sig-param">1)</em>, <em class="sig-param">padding='same'</em>, <em class="sig-param">data_format=None</em>, <em class="sig-param">dilation_rate=(1</em>, <em class="sig-param">1)</em>, <em class="sig-param">activation=None</em>, <em class="sig-param">use_bias=True</em>, <em class="sig-param">kernel_initializer=&lt;deel.lip.initializers.SpectralInitializer object&gt;</em>, <em class="sig-param">bias_initializer='zeros'</em>, <em class="sig-param">kernel_regularizer=None</em>, <em class="sig-param">bias_regularizer=None</em>, <em class="sig-param">activity_regularizer=None</em>, <em class="sig-param">kernel_constraint=None</em>, <em class="sig-param">bias_constraint=None</em>, <em class="sig-param">k_coef_lip=1.0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.FrobeniusConv2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.layers.convolutional.Conv2D</span></code>, <a class="reference internal" href="#deel.lip.layers.LipschitzLayer" title="deel.lip.layers.LipschitzLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">deel.lip.layers.LipschitzLayer</span></code></a>, <a class="reference internal" href="#deel.lip.layers.Condensable" title="deel.lip.layers.Condensable"><code class="xref py py-class docutils literal notranslate"><span class="pre">deel.lip.layers.Condensable</span></code></a></p>
<p>Same as SpectralConv2D but in the case of a single output.</p>
<dl class="method">
<dt id="deel.lip.layers.FrobeniusConv2D.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.FrobeniusConv2D.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="deel.lip.layers.FrobeniusConv2D.call">
<code class="sig-name descname">call</code><a class="headerlink" href="#deel.lip.layers.FrobeniusConv2D.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deel.lip.layers.FrobeniusConv2D.condense">
<code class="sig-name descname">condense</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.FrobeniusConv2D.condense" title="Permalink to this definition">¶</a></dt>
<dd><p>The condense operation allow to overwrite the kernel and ensure that other variables are still consistent.</p>
<p>Returns:</p>
</dd></dl>

<dl class="method">
<dt id="deel.lip.layers.FrobeniusConv2D.get_config">
<code class="sig-name descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.FrobeniusConv2D.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deel.lip.layers.FrobeniusConv2D.vanilla_export">
<code class="sig-name descname">vanilla_export</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.FrobeniusConv2D.vanilla_export" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation allow to turn this Layer to it’s super type, easing storage and serving.</p>
<p>Returns: self as super type</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deel.lip.layers.FrobeniusDense">
<em class="property">class </em><code class="sig-prename descclassname">deel.lip.layers.</code><code class="sig-name descname">FrobeniusDense</code><span class="sig-paren">(</span><em class="sig-param">units</em>, <em class="sig-param">activation=None</em>, <em class="sig-param">use_bias=True</em>, <em class="sig-param">kernel_initializer=&lt;deel.lip.initializers.SpectralInitializer object&gt;</em>, <em class="sig-param">bias_initializer='zeros'</em>, <em class="sig-param">kernel_regularizer=None</em>, <em class="sig-param">bias_regularizer=None</em>, <em class="sig-param">activity_regularizer=None</em>, <em class="sig-param">kernel_constraint=None</em>, <em class="sig-param">bias_constraint=None</em>, <em class="sig-param">k_coef_lip=1.0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.FrobeniusDense" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.layers.core.Dense</span></code>, <a class="reference internal" href="#deel.lip.layers.LipschitzLayer" title="deel.lip.layers.LipschitzLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">deel.lip.layers.LipschitzLayer</span></code></a>, <a class="reference internal" href="#deel.lip.layers.Condensable" title="deel.lip.layers.Condensable"><code class="xref py py-class docutils literal notranslate"><span class="pre">deel.lip.layers.Condensable</span></code></a></p>
<p>Same a SpectralDense, but in the case of a single output.</p>
<dl class="method">
<dt id="deel.lip.layers.FrobeniusDense.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.FrobeniusDense.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="deel.lip.layers.FrobeniusDense.call">
<code class="sig-name descname">call</code><a class="headerlink" href="#deel.lip.layers.FrobeniusDense.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deel.lip.layers.FrobeniusDense.condense">
<code class="sig-name descname">condense</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.FrobeniusDense.condense" title="Permalink to this definition">¶</a></dt>
<dd><p>The condense operation allow to overwrite the kernel and ensure that other variables are still consistent.</p>
<p>Returns:</p>
</dd></dl>

<dl class="method">
<dt id="deel.lip.layers.FrobeniusDense.get_config">
<code class="sig-name descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.FrobeniusDense.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deel.lip.layers.FrobeniusDense.vanilla_export">
<code class="sig-name descname">vanilla_export</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.FrobeniusDense.vanilla_export" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation allow to turn this Layer to it’s super type, easing storage and serving.</p>
<p>Returns: self as super type</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deel.lip.layers.LipschitzLayer">
<em class="property">class </em><code class="sig-prename descclassname">deel.lip.layers.</code><code class="sig-name descname">LipschitzLayer</code><a class="headerlink" href="#deel.lip.layers.LipschitzLayer" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">object</span></code></p>
<p>This class allow to set lipschitz factor of a layer. Lipschitz layer must inherit this class to allow user to set
the lipschitz factor.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>This class only regroup useful functions when developing new Lipschitz layers. But it does not ensure any
property about the layer. This means that inheriting from this class won’t ensure anything about the lipschitz
constant.</p>
</div>
<dl class="attribute">
<dt id="deel.lip.layers.LipschitzLayer.coef_lip">
<code class="sig-name descname">coef_lip</code><em class="property"> = None</em><a class="headerlink" href="#deel.lip.layers.LipschitzLayer.coef_lip" title="Permalink to this definition">¶</a></dt>
<dd><p>define correction coefficient (ie. Lipschitz bound ) of the layer
( multiply the output of the layer by this constant )</p>
</dd></dl>

<dl class="attribute">
<dt id="deel.lip.layers.LipschitzLayer.k_coef_lip">
<code class="sig-name descname">k_coef_lip</code><em class="property"> = 1.0</em><a class="headerlink" href="#deel.lip.layers.LipschitzLayer.k_coef_lip" title="Permalink to this definition">¶</a></dt>
<dd><p>variable used to store the lipschitz factor</p>
</dd></dl>

<dl class="method">
<dt id="deel.lip.layers.LipschitzLayer.set_klip_factor">
<code class="sig-name descname">set_klip_factor</code><span class="sig-paren">(</span><em class="sig-param">klip_factor</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.LipschitzLayer.set_klip_factor" title="Permalink to this definition">¶</a></dt>
<dd><p>Allow to set the lipschitz factor of a layer.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>klip_factor</strong> – the Lipschitz factor the user want to ensure.</p>
</dd>
</dl>
<p>Returns: None</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deel.lip.layers.ScaledAveragePooling2D">
<em class="property">class </em><code class="sig-prename descclassname">deel.lip.layers.</code><code class="sig-name descname">ScaledAveragePooling2D</code><span class="sig-paren">(</span><em class="sig-param">pool_size=(2</em>, <em class="sig-param">2)</em>, <em class="sig-param">strides=None</em>, <em class="sig-param">padding='valid'</em>, <em class="sig-param">data_format=None</em>, <em class="sig-param">k_coef_lip=1.0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.ScaledAveragePooling2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.layers.pooling.AveragePooling2D</span></code>, <a class="reference internal" href="#deel.lip.layers.LipschitzLayer" title="deel.lip.layers.LipschitzLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">deel.lip.layers.LipschitzLayer</span></code></a></p>
<p>Average pooling operation for spatial data, but with a lipschitz bound.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pool_size</strong> – integer or tuple of 2 integers,
factors by which to downscale (vertical, horizontal).
<cite>(2, 2)</cite> will halve the input in both spatial dimension.
If only one integer is specified, the same window length
will be used for both dimensions.</p></li>
<li><p><strong>strides</strong> – Integer, tuple of 2 integers, or None.
Strides values.
If None, it will default to <cite>pool_size</cite>.</p></li>
<li><p><strong>padding</strong> – One of <cite>“valid”</cite> or <cite>“same”</cite> (case-insensitive).</p></li>
<li><p><strong>data_format</strong> – A string,
one of <cite>channels_last</cite> (default) or <cite>channels_first</cite>.
The ordering of the dimensions in the inputs.
<cite>channels_last</cite> corresponds to inputs with shape
<cite>(batch, height, width, channels)</cite> while <cite>channels_first</cite>
corresponds to inputs with shape
<cite>(batch, channels, height, width)</cite>.
It defaults to the <cite>image_data_format</cite> value found in your
Keras config file at <cite>~/.keras/keras.json</cite>.
If you never set it, then it will be “channels_last”.</p></li>
<li><p><strong>k_coef_lip</strong> – the lipschitz factor to ensure</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Input shape:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>If <cite>data_format=’channels_last’</cite>:</dt><dd><p>4D tensor with shape <cite>(batch_size, rows, cols, channels)</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>If <cite>data_format=’channels_first’</cite>:</dt><dd><p>4D tensor with shape <cite>(batch_size, channels, rows, cols)</cite>.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Output shape:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>If <cite>data_format=’channels_last’</cite>:</dt><dd><p>4D tensor with shape <cite>(batch_size, pooled_rows, pooled_cols, channels)</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>If <cite>data_format=’channels_first’</cite>:</dt><dd><p>4D tensor with shape <cite>(batch_size, channels, pooled_rows, pooled_cols)</cite>.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<p>This documentation reuse the body of the original keras.layers.AveragePooling2D doc.</p>
<dl class="method">
<dt id="deel.lip.layers.ScaledAveragePooling2D.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.ScaledAveragePooling2D.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="deel.lip.layers.ScaledAveragePooling2D.call">
<code class="sig-name descname">call</code><a class="headerlink" href="#deel.lip.layers.ScaledAveragePooling2D.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deel.lip.layers.ScaledAveragePooling2D.get_config">
<code class="sig-name descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.ScaledAveragePooling2D.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deel.lip.layers.ScaledGlobalAveragePooling2D">
<em class="property">class </em><code class="sig-prename descclassname">deel.lip.layers.</code><code class="sig-name descname">ScaledGlobalAveragePooling2D</code><span class="sig-paren">(</span><em class="sig-param">data_format=None</em>, <em class="sig-param">k_coef_lip=1.0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.ScaledGlobalAveragePooling2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D</span></code>, <a class="reference internal" href="#deel.lip.layers.LipschitzLayer" title="deel.lip.layers.LipschitzLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">deel.lip.layers.LipschitzLayer</span></code></a></p>
<p>Global average pooling operation for spatial data with Lipschitz bound.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>data_format</strong> – A string,
one of <cite>channels_last</cite> (default) or <cite>channels_first</cite>.
The ordering of the dimensions in the inputs.
<cite>channels_last</cite> corresponds to inputs with shape
<cite>(batch, height, width, channels)</cite> while <cite>channels_first</cite>
corresponds to inputs with shape
<cite>(batch, channels, height, width)</cite>.
It defaults to the <cite>image_data_format</cite> value found in your
Keras config file at <cite>~/.keras/keras.json</cite>.
If you never set it, then it will be “channels_last”.</p>
</dd>
</dl>
<dl class="simple">
<dt>Input shape:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>If <cite>data_format=’channels_last’</cite>:</dt><dd><p>4D tensor with shape <cite>(batch_size, rows, cols, channels)</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>If <cite>data_format=’channels_first’</cite>:</dt><dd><p>4D tensor with shape <cite>(batch_size, channels, rows, cols)</cite>.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<p>Output shape:
2D tensor with shape <cite>(batch_size, channels)</cite>.</p>
<p>This documentation reuse the body of the original keras.layers.GlobalAveragePooling doc.</p>
<dl class="method">
<dt id="deel.lip.layers.ScaledGlobalAveragePooling2D.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.ScaledGlobalAveragePooling2D.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="deel.lip.layers.ScaledGlobalAveragePooling2D.call">
<code class="sig-name descname">call</code><a class="headerlink" href="#deel.lip.layers.ScaledGlobalAveragePooling2D.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deel.lip.layers.ScaledGlobalAveragePooling2D.get_config">
<code class="sig-name descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.ScaledGlobalAveragePooling2D.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deel.lip.layers.ScaledL2NormPooling2D">
<em class="property">class </em><code class="sig-prename descclassname">deel.lip.layers.</code><code class="sig-name descname">ScaledL2NormPooling2D</code><span class="sig-paren">(</span><em class="sig-param">pool_size=(2</em>, <em class="sig-param">2)</em>, <em class="sig-param">strides=None</em>, <em class="sig-param">padding='valid'</em>, <em class="sig-param">data_format=None</em>, <em class="sig-param">k_coef_lip=1.0</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.ScaledL2NormPooling2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.layers.pooling.AveragePooling2D</span></code>, <a class="reference internal" href="#deel.lip.layers.LipschitzLayer" title="deel.lip.layers.LipschitzLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">deel.lip.layers.LipschitzLayer</span></code></a></p>
<p>Average pooling operation for spatial data, with a lipschitz bound. This pooling operation is norm preserving
(aka gradient=1 almost everywhere).</p>
<p>[1]Y.-L.Boureau, J.Ponce, et Y.LeCun, « A Theoretical Analysis of Feature Pooling in Visual Recognition »,p.8.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>pool_size</strong> – integer or tuple of 2 integers,
factors by which to downscale (vertical, horizontal).
<cite>(2, 2)</cite> will halve the input in both spatial dimension.
If only one integer is specified, the same window length
will be used for both dimensions.</p></li>
<li><p><strong>strides</strong> – Integer, tuple of 2 integers, or None.
Strides values.
If None, it will default to <cite>pool_size</cite>.</p></li>
<li><p><strong>padding</strong> – One of <cite>“valid”</cite> or <cite>“same”</cite> (case-insensitive).</p></li>
<li><p><strong>data_format</strong> – A string,
one of <cite>channels_last</cite> (default) or <cite>channels_first</cite>.
The ordering of the dimensions in the inputs.
<cite>channels_last</cite> corresponds to inputs with shape
<cite>(batch, height, width, channels)</cite> while <cite>channels_first</cite>
corresponds to inputs with shape
<cite>(batch, channels, height, width)</cite>.
It defaults to the <cite>image_data_format</cite> value found in your
Keras config file at <cite>~/.keras/keras.json</cite>.
If you never set it, then it will be “channels_last”.</p></li>
<li><p><strong>k_coef_lip</strong> – the lipschitz factor to ensure</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Input shape:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>If <cite>data_format=’channels_last’</cite>:</dt><dd><p>4D tensor with shape <cite>(batch_size, rows, cols, channels)</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>If <cite>data_format=’channels_first’</cite>:</dt><dd><p>4D tensor with shape <cite>(batch_size, channels, rows, cols)</cite>.</p>
</dd>
</dl>
</li>
</ul>
</dd>
<dt>Output shape:</dt><dd><ul class="simple">
<li><dl class="simple">
<dt>If <cite>data_format=’channels_last’</cite>:</dt><dd><p>4D tensor with shape <cite>(batch_size, pooled_rows, pooled_cols, channels)</cite>.</p>
</dd>
</dl>
</li>
<li><dl class="simple">
<dt>If <cite>data_format=’channels_first’</cite>:</dt><dd><p>4D tensor with shape <cite>(batch_size, channels, pooled_rows, pooled_cols)</cite>.</p>
</dd>
</dl>
</li>
</ul>
</dd>
</dl>
<dl class="method">
<dt id="deel.lip.layers.ScaledL2NormPooling2D.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.ScaledL2NormPooling2D.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="deel.lip.layers.ScaledL2NormPooling2D.call">
<code class="sig-name descname">call</code><a class="headerlink" href="#deel.lip.layers.ScaledL2NormPooling2D.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deel.lip.layers.ScaledL2NormPooling2D.get_config">
<code class="sig-name descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.ScaledL2NormPooling2D.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deel.lip.layers.SpectralConv2D">
<em class="property">class </em><code class="sig-prename descclassname">deel.lip.layers.</code><code class="sig-name descname">SpectralConv2D</code><span class="sig-paren">(</span><em class="sig-param">filters</em>, <em class="sig-param">kernel_size</em>, <em class="sig-param">strides=(1</em>, <em class="sig-param">1)</em>, <em class="sig-param">padding='same'</em>, <em class="sig-param">data_format=None</em>, <em class="sig-param">dilation_rate=(1</em>, <em class="sig-param">1)</em>, <em class="sig-param">activation=None</em>, <em class="sig-param">use_bias=True</em>, <em class="sig-param">kernel_initializer=&lt;deel.lip.initializers.BjorckInitializer object&gt;</em>, <em class="sig-param">bias_initializer='zeros'</em>, <em class="sig-param">kernel_regularizer=None</em>, <em class="sig-param">bias_regularizer=None</em>, <em class="sig-param">activity_regularizer=None</em>, <em class="sig-param">kernel_constraint=None</em>, <em class="sig-param">bias_constraint=None</em>, <em class="sig-param">k_coef_lip=1.0</em>, <em class="sig-param">niter_spectral=3</em>, <em class="sig-param">niter_bjorck=15</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.SpectralConv2D" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.layers.convolutional.Conv2D</span></code>, <a class="reference internal" href="#deel.lip.layers.LipschitzLayer" title="deel.lip.layers.LipschitzLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">deel.lip.layers.LipschitzLayer</span></code></a>, <a class="reference internal" href="#deel.lip.layers.Condensable" title="deel.lip.layers.Condensable"><code class="xref py py-class docutils literal notranslate"><span class="pre">deel.lip.layers.Condensable</span></code></a></p>
<p>This class is a Conv2D Layer constrained such that all singular of it’s kernel are 1. The computation based on
BjorckNormalizer algorithm. As this is not enough to ensure 1 Lipschitzity a coertive coefficient is applied on the
output.
The computation is done in three steps:</p>
<ol class="arabic simple">
<li><p>reduce the largest singular value to 1, using iterated power method.</p></li>
<li><p>increase other singular values to 1, using BjorckNormalizer algorithm.</p></li>
<li><p>divide the output by the Lipschitz bound to ensure k Lipschitzity.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>filters</strong> – Integer, the dimensionality of the output space
(i.e. the number of output filters in the convolution).</p></li>
<li><p><strong>kernel_size</strong> – An integer or tuple/list of 2 integers, specifying the
height and width of the 2D convolution window.
Can be a single integer to specify the same value for
all spatial dimensions.</p></li>
<li><p><strong>strides</strong> – An integer or tuple/list of 2 integers,
specifying the strides of the convolution along the height and width.
Can be a single integer to specify the same value for
all spatial dimensions.
Specifying any stride value != 1 is incompatible with specifying
any <cite>dilation_rate</cite> value != 1.</p></li>
<li><p><strong>padding</strong> – one of <cite>“valid”</cite> or <cite>“same”</cite> (case-insensitive).</p></li>
<li><p><strong>data_format</strong> – A string,
one of <cite>channels_last</cite> (default) or <cite>channels_first</cite>.
The ordering of the dimensions in the inputs.
<cite>channels_last</cite> corresponds to inputs with shape
<cite>(batch, height, width, channels)</cite> while <cite>channels_first</cite>
corresponds to inputs with shape
<cite>(batch, channels, height, width)</cite>.
It defaults to the <cite>image_data_format</cite> value found in your
Keras config file at <cite>~/.keras/keras.json</cite>.
If you never set it, then it will be “channels_last”.</p></li>
<li><p><strong>dilation_rate</strong> – an integer or tuple/list of 2 integers, specifying
the dilation rate to use for dilated convolution.
Can be a single integer to specify the same value for
all spatial dimensions.
Currently, specifying any <cite>dilation_rate</cite> value != 1 is
incompatible with specifying any stride value != 1.</p></li>
<li><p><strong>activation</strong> – Activation function to use.
If you don’t specify anything, no activation is applied
(ie. “linear” activation: <cite>a(x) = x</cite>).</p></li>
<li><p><strong>use_bias</strong> – Boolean, whether the layer uses a bias vector.</p></li>
<li><p><strong>kernel_initializer</strong> – Initializer for the <cite>kernel</cite> weights matrix.</p></li>
<li><p><strong>bias_initializer</strong> – Initializer for the bias vector.</p></li>
<li><p><strong>kernel_regularizer</strong> – Regularizer function applied to
the <cite>kernel</cite> weights matrix.</p></li>
<li><p><strong>bias_regularizer</strong> – Regularizer function applied to the bias vector.</p></li>
<li><p><strong>activity_regularizer</strong> – Regularizer function applied to
the output of the layer (its “activation”)..</p></li>
<li><p><strong>kernel_constraint</strong> – Constraint function applied to the kernel matrix.</p></li>
<li><p><strong>bias_constraint</strong> – Constraint function applied to the bias vector.</p></li>
<li><p><strong>k_coef_lip</strong> – lipschitz constant to ensure</p></li>
<li><p><strong>niter_spectral</strong> – number of iteration to find the maximum singular value.</p></li>
<li><p><strong>niter_bjorck</strong> – number of iteration with BjorckNormalizer algorithm.</p></li>
</ul>
</dd>
</dl>
<p>This documentation reuse the body of the original keras.layers.Conv2D doc.</p>
<dl class="method">
<dt id="deel.lip.layers.SpectralConv2D.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.SpectralConv2D.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="deel.lip.layers.SpectralConv2D.call">
<code class="sig-name descname">call</code><a class="headerlink" href="#deel.lip.layers.SpectralConv2D.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deel.lip.layers.SpectralConv2D.condense">
<code class="sig-name descname">condense</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.SpectralConv2D.condense" title="Permalink to this definition">¶</a></dt>
<dd><p>The condense operation allow to overwrite the kernel and ensure that other variables are still consistent.</p>
<p>Returns:</p>
</dd></dl>

<dl class="method">
<dt id="deel.lip.layers.SpectralConv2D.get_config">
<code class="sig-name descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.SpectralConv2D.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deel.lip.layers.SpectralConv2D.vanilla_export">
<code class="sig-name descname">vanilla_export</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.SpectralConv2D.vanilla_export" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation allow to turn this Layer to it’s super type, easing storage and serving.</p>
<p>Returns: self as super type</p>
</dd></dl>

</dd></dl>

<dl class="class">
<dt id="deel.lip.layers.SpectralDense">
<em class="property">class </em><code class="sig-prename descclassname">deel.lip.layers.</code><code class="sig-name descname">SpectralDense</code><span class="sig-paren">(</span><em class="sig-param">units</em>, <em class="sig-param">activation=None</em>, <em class="sig-param">use_bias=True</em>, <em class="sig-param">kernel_initializer=&lt;deel.lip.initializers.BjorckInitializer object&gt;</em>, <em class="sig-param">bias_initializer='zeros'</em>, <em class="sig-param">kernel_regularizer=None</em>, <em class="sig-param">bias_regularizer=None</em>, <em class="sig-param">activity_regularizer=None</em>, <em class="sig-param">kernel_constraint=None</em>, <em class="sig-param">bias_constraint=None</em>, <em class="sig-param">k_coef_lip=1.0</em>, <em class="sig-param">niter_spectral=3</em>, <em class="sig-param">niter_bjorck=15</em>, <em class="sig-param">**kwargs</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.SpectralDense" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">tensorflow.python.keras.layers.core.Dense</span></code>, <a class="reference internal" href="#deel.lip.layers.LipschitzLayer" title="deel.lip.layers.LipschitzLayer"><code class="xref py py-class docutils literal notranslate"><span class="pre">deel.lip.layers.LipschitzLayer</span></code></a>, <a class="reference internal" href="#deel.lip.layers.Condensable" title="deel.lip.layers.Condensable"><code class="xref py py-class docutils literal notranslate"><span class="pre">deel.lip.layers.Condensable</span></code></a></p>
<p>This class is a Dense Layer constrained such that all singular of it’s kernel are 1. The computation based on
BjorckNormalizer algorithm.
The computation is done in two steps:</p>
<ol class="arabic simple">
<li><p>reduce the larget singular value to 1, using iterated power method.</p></li>
<li><p>increase other singular values to 1, using BjorckNormalizer algorithm.</p></li>
</ol>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>units</strong> – Positive integer, dimensionality of the output space.</p></li>
<li><p><strong>activation</strong> – Activation function to use.
If you don’t specify anything, no activation is applied
(ie. “linear” activation: <cite>a(x) = x</cite>).</p></li>
<li><p><strong>use_bias</strong> – Boolean, whether the layer uses a bias vector.</p></li>
<li><p><strong>kernel_initializer</strong> – Initializer for the <cite>kernel</cite> weights matrix.</p></li>
<li><p><strong>bias_initializer</strong> – Initializer for the bias vector.</p></li>
<li><p><strong>kernel_regularizer</strong> – Regularizer function applied to
the <cite>kernel</cite> weights matrix.</p></li>
<li><p><strong>bias_regularizer</strong> – Regularizer function applied to the bias vector.</p></li>
<li><p><strong>activity_regularizer</strong> – Regularizer function applied to
the output of the layer (its “activation”)..</p></li>
<li><p><strong>kernel_constraint</strong> – Constraint function applied to
the <cite>kernel</cite> weights matrix.</p></li>
<li><p><strong>bias_constraint</strong> – Constraint function applied to the bias vector.</p></li>
<li><p><strong>k_coef_lip</strong> – lipschitz constant to ensure</p></li>
<li><p><strong>niter_spectral</strong> – number of iteration to find the maximum singular value.</p></li>
<li><p><strong>niter_bjorck</strong> – number of iteration with BjorckNormalizer algorithm.</p></li>
</ul>
</dd>
</dl>
<dl class="simple">
<dt>Input shape:</dt><dd><p>N-D tensor with shape: <cite>(batch_size, …, input_dim)</cite>.
The most common situation would be
a 2D input with shape <cite>(batch_size, input_dim)</cite>.</p>
</dd>
<dt>Output shape:</dt><dd><p>N-D tensor with shape: <cite>(batch_size, …, units)</cite>.
For instance, for a 2D input with shape <cite>(batch_size, input_dim)</cite>,
the output would have shape <cite>(batch_size, units)</cite>.</p>
</dd>
</dl>
<p>This documentation reuse the body of the original keras.layers.Dense doc.</p>
<dl class="method">
<dt id="deel.lip.layers.SpectralDense.build">
<code class="sig-name descname">build</code><span class="sig-paren">(</span><em class="sig-param">input_shape</em><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.SpectralDense.build" title="Permalink to this definition">¶</a></dt>
<dd><p>Creates the variables of the layer (optional, for subclass implementers).</p>
<p>This is a method that implementers of subclasses of <cite>Layer</cite> or <cite>Model</cite>
can override if they need a state-creation step in-between
layer instantiation and layer call.</p>
<p>This is typically used to create the weights of <cite>Layer</cite> subclasses.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><p><strong>input_shape</strong> – Instance of <cite>TensorShape</cite>, or list of instances of
<cite>TensorShape</cite> if the layer expects a list of inputs
(one instance per input).</p>
</dd>
</dl>
</dd></dl>

<dl class="attribute">
<dt id="deel.lip.layers.SpectralDense.call">
<code class="sig-name descname">call</code><a class="headerlink" href="#deel.lip.layers.SpectralDense.call" title="Permalink to this definition">¶</a></dt>
<dd></dd></dl>

<dl class="method">
<dt id="deel.lip.layers.SpectralDense.condense">
<code class="sig-name descname">condense</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.SpectralDense.condense" title="Permalink to this definition">¶</a></dt>
<dd><p>The condense operation allow to overwrite the kernel and ensure that other variables are still consistent.</p>
<p>Returns:</p>
</dd></dl>

<dl class="method">
<dt id="deel.lip.layers.SpectralDense.get_config">
<code class="sig-name descname">get_config</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.SpectralDense.get_config" title="Permalink to this definition">¶</a></dt>
<dd><p>Returns the config of the layer.</p>
<p>A layer config is a Python dictionary (serializable)
containing the configuration of a layer.
The same layer can be reinstantiated later
(without its trained weights) from this configuration.</p>
<p>The config of a layer does not include connectivity
information, nor the layer class name. These are handled
by <cite>Network</cite> (one layer of abstraction above).</p>
<dl class="field-list simple">
<dt class="field-odd">Returns</dt>
<dd class="field-odd"><p>Python dictionary.</p>
</dd>
</dl>
</dd></dl>

<dl class="method">
<dt id="deel.lip.layers.SpectralDense.vanilla_export">
<code class="sig-name descname">vanilla_export</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#deel.lip.layers.SpectralDense.vanilla_export" title="Permalink to this definition">¶</a></dt>
<dd><p>This operation allow to turn this Layer to it’s super type, easing storage and serving.</p>
<p>Returns: self as super type</p>
</dd></dl>

</dd></dl>

</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="deel.lip.losses.html" class="btn btn-neutral float-right" title="deel.lip.losses module" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right"></span></a>
      
      
        <a href="deel.lip.initializers.html" class="btn btn-neutral float-left" title="deel.lip.initializers module" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2020, SERRURIER Mathieu (mathieu.serrurier@irt-saintexupery.com),
MAMALET Franck (franck.mamalet@irt-saintexupery.com),
BOISSIN Thibaut (thibaut.boissin@irt-saintexupery.com)

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>